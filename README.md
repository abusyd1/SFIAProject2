# Simple Footballer Generator
### _A simple app in which you can generate a Football player_

## Project Brief
According to the project specification, the objective of this project is to create a simple web application, made up of 4 services:
* Service 1 - Communicates with other 3 services, renders Jinja2 templates to interact with application, persists data in an SQL database
* Servies 2 & 3 - Generate random objects
* Service 4 - Generates another object, based upon the results of Services 2 & 3
The application will also encapsulate the following:
* Asana Board
* Feature-Branch model within GitHub, subsequently built through CI Server (Jenkins) and deployed to a cloud-based virtual machine
* Jenkins webhook to recreate and redeploy changes
* Deployed using containerisation and an orchestration tool (Docker)
* Ansible Playbook to provision enviornment for application to run
* Reverse Proxy (NGINX) 

For this project, I will be creating a Footballer Generator, where:
* Service 2 generates a position
* Service 3 generates a nationality 
* Service 4 generates a profile of the player, which includes a 'quality' (based on the generated position) and a 'team', (based on their nationality)
* Service 1: the above services are then all put together and displayed on a page on service 1
* The above is true for Version 1 of my app. Version 2 changes Service 4 so that a monetary value of the player is also generated.

## Project Planning
An ASANA board was used to plan this project. It can be seen below, detailing all tasks in their relative categories:

<img width="685" alt="asana" src="https://user-images.githubusercontent.com/77271496/109600845-bcfa9300-7b15-11eb-929f-6ac07afe6f43.png">

The full board can be seen here: https://app.asana.com/0/1199964190647334/board


## Software Design
A combination of a wide variety of software has been used in the creation of this app, as will be explained below.

### Entity Diagram
The entity diagram used for this project is shown below, in tabular form. This table is stored within a MYSQL Database, which in this case was an integrated GCP database.

<img width="300" alt="ED Table" src="https://user-images.githubusercontent.com/77271496/109592069-92550e00-7b06-11eb-83ec-0faec0df7e4e.png">

## Services
Below can be seen how the different services of this application communicated with eachother, as I mentioned above briefly. 

<img width="509" alt="Services" src="https://user-images.githubusercontent.com/77271496/109593296-95e99480-7b08-11eb-9ca2-7a16e73cae5c.png">

As can be seen, the green arrows indicate a 'position' generated by service 2, which service 1 gets with a GET request and is then posted to service 4 with a POST request. The blue arrow indicates a 'nationality' which follows the same direction. The purple arrow generates a 'profile' for the player, which is a descriptor based on the information retrieved from services 2 & 3. Service 1 takes all of this and displays it in the front end, to the user.

## CI Pipeline
Below can be seen a visual representation of how all the software within the project connect within a CI pipeline.

<img width="553" alt="Pipeline" src="https://user-images.githubusercontent.com/77271496/109594205-4906bd80-7b0a-11eb-8c53-feff173b7037.png">

This diagram demonstrates that the code for the application was first developed on Flask and then pushed to my repository within GitHub. All changes specific to version 1 of my app were pushed to 'version1' branch, whilst changes for version 2 were pushed to 'version2'. Whilst these changes were being commited, I would then update my Asana board and update/add statuses for relevant tasks, and then use that to determine the next. The idea was that at the same time, Jenkins would use the webhook feature to automatically pull code down. However, my Jenkins build failed, so this could not happen. I did not manage to fix these problems before the submission deadline for this project. However, I can see where the problems arised, and I will try to fix these in future.

There were a number of reasons for failing the Pipeline job, as I will show below. 

<img width="935" alt="Jenkins" src="https://user-images.githubusercontent.com/77271496/109596187-a51f1100-7b0d-11eb-8272-c676172a85a5.png">

This shows the exact stages within the my Pipeline that failed. As can be seen, the Build-Image stage was where the failure occured, and due to this, the next stage automatically failed. 
Taking a deeper look into this, the Console Output from Jenkins shows the following: 

<img width="891" alt="Failure" src="https://user-images.githubusercontent.com/77271496/109596422-237bb300-7b0e-11eb-805c-7a7b07bf6a49.png">

This output displays a number of problems. Firstly, the environment variables for DB_URI and SEC_KEY for the connection to the database were not set in Jenkins, which would stop the Service 1 from working as it uses a database connection. In addition, there was another problem in pushing the images created by 'docker-compose' to Dockerhub. This could have been because the credentials for my Dockerhub account were not set properly.

Despite the problems with the Build-Stage in Jenkins, the testing for services 2 and 3. Moreover, I was able to manually run the app using docker stack commands. I will demonstrate the working aspects of the build below:

<img width="461" alt="service2 test" src="https://user-images.githubusercontent.com/77271496/109598018-4f983380-7b10-11eb-9051-4ceb20ae7b38.png">

This shows that the testing for service 1 failed (due to environment variables not being set in Jenkins, as mentioned above), but service 2 passed.

<img width="464" alt="service3" src="https://user-images.githubusercontent.com/77271496/109598144-9be37380-7b10-11eb-923b-7fd3cc4f9259.png">

This shows the testing for service 3 also passing.

## Swarm
As mentioned earlier, I was able to deploy a stack manually and get the apps to run. This stage made use of NGINX as a Load-Balancer as well as a reverse-proxy, to make the app accessible to the user. Outside of Jenkins, the manual running of the Ansible Playbook worked, to create the swarm. For this app, I had a manager node and 2 worker nodes, and each service had 4 replicas. The manager node would pull the services from Dockerhub, and distribute them amongst the workers and itself. The tasks run in each node were copies of each container for a service. This is apparent so that 1 container wouldn't be overloaded with traffic and if so, the app would continue to run as there are replicas of each service. NGINX acts as a reverse proxy, so that the app would be accessible on it's own IP and port, rather than being accessed directly with the front/back end servers. This is important for security purposes. The Load-Balancer worked so that the any loads would get forwarded to the server/s with least connections. This ensures an equally distributed load and prevents any traffic overload. 

## Risk Assessment
### Initial Risk Assessment
Below can be seen the initial Risk Assessment for this project:

<img width="574" alt="risk1" src="https://user-images.githubusercontent.com/77271496/109601421-be788b00-7b16-11eb-95eb-bc7c18b3e8ab.png">

### Final Risk Assessment
Below can be seen the final Risk Assessment for this project:

<img width="577" alt="risk2" src="https://user-images.githubusercontent.com/77271496/109601971-bb31cf00-7b17-11eb-8e55-5cb3086a27e4.png">












